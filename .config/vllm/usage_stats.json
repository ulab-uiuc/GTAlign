{"uuid": "eb5a87d6-0be2-4f71-9c67-d502f4e3b0ee", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8457C", "cpu_family_model_stepping": "6,143,8", "total_memory": 2163315744768, "architecture": "x86_64", "platform": "Linux-5.10.135.bsk.6-amd64-x86_64-with-glibc2.36", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA H20", "gpu_memory_per_device": 102010781696, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5.post1", "context": "ENGINE_CONTEXT", "log_time": 1756946198713597184, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.5, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "89455f97-c1c2-4690-bc96-e89bcadc4b50", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8457C", "cpu_family_model_stepping": "6,143,8", "total_memory": 2163315744768, "architecture": "x86_64", "platform": "Linux-5.10.135.bsk.6-amd64-x86_64-with-glibc2.36", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA H20", "gpu_memory_per_device": 102010781696, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5.post1", "context": "ENGINE_CONTEXT", "log_time": 1756948870575581952, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 4, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "89455f97-c1c2-4690-bc96-e89bcadc4b50", "log_time": 1756949475811096832}
{"uuid": "89455f97-c1c2-4690-bc96-e89bcadc4b50", "log_time": 1756950081053793024}
{"uuid": "89455f97-c1c2-4690-bc96-e89bcadc4b50", "log_time": 1756950686429615872}
{"uuid": "56bd4202-e5b1-4b59-9d9a-456e7afc6461", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8457C", "cpu_family_model_stepping": "6,143,8", "total_memory": 2163315765248, "architecture": "x86_64", "platform": "Linux-5.10.135.bsk.6-amd64-x86_64-with-glibc2.36", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA H20", "gpu_memory_per_device": 102010781696, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5.post1", "context": "ENGINE_CONTEXT", "log_time": 1757097185111309056, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "46361e00-078e-4751-b09a-38cc0000c958", "provider": "UNKNOWN", "num_cpu": 192, "cpu_type": "Intel(R) Xeon(R) Platinum 8457C", "cpu_family_model_stepping": "6,143,8", "total_memory": 2163315765248, "architecture": "x86_64", "platform": "Linux-5.10.135.bsk.6-amd64-x86_64-with-glibc2.36", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA H20", "gpu_memory_per_device": 102010781696, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5.post1", "context": "ENGINE_CONTEXT", "log_time": 1757099985002017024, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 1, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "46361e00-078e-4751-b09a-38cc0000c958", "log_time": 1757100590238642944}
